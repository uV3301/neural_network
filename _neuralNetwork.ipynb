{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple algebraic expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0908 12:29:23.520070 22388 deprecation.py:506] From C:\\Users\\uV\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=([1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow.python.keras.api._v1.keras.optimizers' from 'C:\\\\Users\\\\uV\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\keras\\\\api\\\\_v1\\\\keras\\\\optimizers\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'sgd', loss='mean_squared_error' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs =np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)\n",
    "ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 0s 13ms/sample - loss: 48.1053\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 38.2338\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 30.4594\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 173us/sample - loss: 24.3351\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 19.5091\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 15.7049\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 12.7045\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 164us/sample - loss: 10.3368\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.4670\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 6.9891\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.8196\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 159us/sample - loss: 4.8929\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 4.1574\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 3.5724\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.1059\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 159us/sample - loss: 2.7329\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 2.4334\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 2.1920\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 1.9964\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.8369\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.7060\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 327us/sample - loss: 1.5976\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.5071\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.4307\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.3656\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 1.3095\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.2605\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.2172\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.1785\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.1435\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 832us/sample - loss: 1.1116\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.0821\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.0546\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.0288\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 1.0044\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 159us/sample - loss: 0.9813\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.9591\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.9378\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 0.9173\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.8975\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.8783\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 163us/sample - loss: 0.8596\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.8415\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.8238\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 171us/sample - loss: 0.8066\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.7898\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 159us/sample - loss: 0.7734\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.7574\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.7417\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.7264\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.7114\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 664us/sample - loss: 0.6967\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.6824\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.6683\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.6546\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.6411\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 502us/sample - loss: 0.6279\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.6150\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.6024\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.5900\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.5779\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5660\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5544\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.5430\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.5318\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.5209\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.5102\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.4997\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.4894\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4794\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.4695\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.4599\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.4504\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.4412\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.4321\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.4233\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4146\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.4060\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3977\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3895\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3815\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3737\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3660\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3585\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3511\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.3439\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3369\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3299\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 0.3232\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3165\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.3100\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3037\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2974\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 838us/sample - loss: 0.2913\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2853\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2795\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2737\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2681\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.2572\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 0.2519\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2467\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2417\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2367\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2319\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2271\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2224\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2179\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2134\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2090\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.2047\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.2005\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1964\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1923\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1884\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1845\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.1807\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1770\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1734\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1698\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1663\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 665us/sample - loss: 0.1629\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1596\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1563\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.1531\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1499\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1469\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1438\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1409\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1380\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1352\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.1324\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.1297\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1270\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1244\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1218\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1193\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 830us/sample - loss: 0.1169\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1145\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1121\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1098\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.1076\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.1054\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1032\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1011\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0990\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 832us/sample - loss: 0.0970\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0950\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0930\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0911\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0892\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 664us/sample - loss: 0.0874\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0856\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0839\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.0821\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.0804\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.0788\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0772\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0756\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0740\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.0725\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.0710\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0696\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0681\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0667\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0654\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.0640\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0627\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0614\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0602\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0589\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0577\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.0565\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0554\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0542\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0531\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0520\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0510\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 663us/sample - loss: 0.0499\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0489\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0479\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0469\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0459\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0450\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 0.0441\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0432\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0423\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0414\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0406\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0397\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.0389\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0381\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0373\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0366\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0358\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0351\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 0.0336\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0330\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0323\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0316\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0310\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0303\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.0297\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0291\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0285\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 169us/sample - loss: 0.0279\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0273\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0268\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.0262\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0257\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0252\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0246\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0241\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0236\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 665us/sample - loss: 0.0232\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0227\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0222\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0218\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0213\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0209\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 663us/sample - loss: 0.0204\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0200\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0196\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0192\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0188\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0184\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.0181\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0177\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0173\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0170\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0166\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0163\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.0159\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0156\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 0.0153\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0150\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0147\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 834us/sample - loss: 0.0144\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0141\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0138\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0135\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0132\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0130\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 663us/sample - loss: 0.0127\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0124\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0122\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0119\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0117\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.0114\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0112\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0110\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0107\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0105\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 0.0103\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.0101\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0099\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0097\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0095\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0093\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 832us/sample - loss: 0.0091\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0089\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0087\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0086\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0084\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.0082\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 0.0080\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0079\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0077\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0076\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.0074\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 830us/sample - loss: 0.0072\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0071\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0069\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0068\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 164us/sample - loss: 0.0067\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0065\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.0064\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0063\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0061\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0060\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0059\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0058\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0056\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 497us/sample - loss: 0.0055\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0054\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0053\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0052\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0051\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0050\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.0049\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0048\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.0047\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0046\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0044\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 669us/sample - loss: 0.0043\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0042\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0041\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0041\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0040\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 502us/sample - loss: 0.0039\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.0038\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.0037\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0037\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0036\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0035\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0034\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0034\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0033\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0032\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0032\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0031\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 0.0030\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0030\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0029\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0028\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0028\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.0027\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 0.0027\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0026\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0026\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0025\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0025\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0024\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0024\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0023\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0023\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0022\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0022\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0021\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 0.0021\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0020\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0020\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0020\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0019\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0019\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 0.0018\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0018\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0018\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0017\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0017\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0017\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.0016\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0016\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0016\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0015\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0015\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0015\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0014\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.0014\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0014\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0013\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0013\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0013\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0013\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 830us/sample - loss: 0.0012\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0012\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0012\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.0012\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.0011\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0011\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 0.0011\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0011\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0011\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.0010\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0010\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.8773e-04\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 9.6743e-04\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 9.4756e-04\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 834us/sample - loss: 9.2810e-04\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 9.0904e-04\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.9037e-04\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.7208e-04\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 8.5417e-04\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 8.3662e-04\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 498us/sample - loss: 8.1944e-04\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.0260e-04\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.8612e-04\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.6997e-04\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 335us/sample - loss: 7.5415e-04\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.3866e-04\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.2349e-04\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.0863e-04\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.9407e-04\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 6.7982e-04\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 6.6585e-04\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 6.5218e-04\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.3878e-04\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 6.2566e-04\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 6.1281e-04\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 6.0022e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 5.8789e-04\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 5.7581e-04\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 5.6399e-04\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 5.5240e-04\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 5.4105e-04\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 5.2994e-04\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 5.1905e-04\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 5.0839e-04\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 4.9795e-04\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 4.8772e-04\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 4.7770e-04\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.6789e-04\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.5828e-04\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 832us/sample - loss: 4.4886e-04\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 4.3964e-04\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 4.3061e-04\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 4.2176e-04\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 4.1310e-04\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 336us/sample - loss: 4.0462e-04\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 3.9631e-04\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 3.8817e-04\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.8019e-04\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.7239e-04\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.6474e-04\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 3.5725e-04\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.4991e-04\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.4272e-04\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.3568e-04\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.2878e-04\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.2203e-04\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 3.1542e-04\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 3.0894e-04\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 3.0259e-04\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.9638e-04\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.9029e-04\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 2.8432e-04\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.7848e-04\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.7276e-04\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.6716e-04\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.6167e-04\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 2.5630e-04\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 2.5104e-04\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 2.4588e-04\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 2.4083e-04\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.3588e-04\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.3104e-04\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.2629e-04\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 2.2164e-04\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.1709e-04\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 2.1263e-04\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 163us/sample - loss: 2.0826e-04\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 2.0399e-04\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.9980e-04\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.9569e-04\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.9167e-04\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.8773e-04\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.8388e-04\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 1.8010e-04\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 165us/sample - loss: 1.7640e-04\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.7278e-04\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 1.6923e-04\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 161us/sample - loss: 1.6575e-04\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.6235e-04\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.5901e-04\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.5575e-04\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.5255e-04\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.4941e-04\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 1.4635e-04\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.4334e-04\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.4040e-04\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.3751e-04\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.3469e-04\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.3192e-04\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.2921e-04\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.2656e-04\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.2396e-04\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.2141e-04\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.1892e-04\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.1647e-04\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.1408e-04\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 1.1174e-04\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 665us/sample - loss: 1.0944e-04\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 1.0720e-04\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 1.0500e-04\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 1.0284e-04\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.0073e-04\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 9.8657e-05\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.6629e-05\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 169us/sample - loss: 9.4646e-05\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 9.2702e-05\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 9.0797e-05\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.8932e-05\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 8.7106e-05\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.5316e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.3563e-05\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 331us/sample - loss: 8.1848e-05\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 8.0166e-05\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.8520e-05\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 7.6907e-05\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.5328e-05\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 7.3781e-05\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 330us/sample - loss: 7.2265e-05\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 7.0781e-05\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 6.9327e-05\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.7902e-05\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 6.6508e-05\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 6.5141e-05\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.3804e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d04f3cf518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs,ys,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.976696]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hell():\n",
    "    ls = []\n",
    "    for i in A:\n",
    "        ls.append(2*i-1)\n",
    "    ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0070943]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognizing clothing from fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_ = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = fashion_.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 \n",
      " 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels),'\\n',len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   1   0   0   9   6   0   0   0  24   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  67 209 231 248 252 250 253 246 206\n",
      "  132   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1 227 243 234 234 248 246 238 230 234\n",
      "  250 126   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  57 231 213 227 234 232 231 235 232 218\n",
      "  218 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  90 239 207 213 236 235 232 232 229 210\n",
      "  215 207   6   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 211 245 229 197 220 221 221 222 203 221\n",
      "  235 222  96   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  55 154 239 213 217 218 214 215 215 199\n",
      "  235 167  61   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  17 238 220 221 215 210 249  98\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0 225 220 214 211 215 251 112\n",
      "    0   2   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0 208 218 218 224 210 221 100\n",
      "    0   4   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0  16 213 244 255 218 204 218 143\n",
      "    0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0  76 232 235 234 218 211 220 223\n",
      "    0   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 161 225 218 218 220 206 209 213\n",
      "   32   0   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 214 218 222 221 218 210 207 217\n",
      "   89   0   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 207 211 225 218 218 209 208 217\n",
      "  165   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  44 221 206 225 218 218 210 207 215\n",
      "  203   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  79 227 204 224 222 216 211 210 210\n",
      "  196   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 103 232 203 225 222 216 211 214 208\n",
      "  204   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 137 235 203 225 222 217 210 214 209\n",
      "  211  15   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 167 234 202 223 223 220 210 214 209\n",
      "  215  44   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 185 235 203 224 224 220 210 216 213\n",
      "  221  66   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 197 237 193 225 224 218 209 217 213\n",
      "  223  88   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 224 242 189 224 227 223 209 217 214\n",
      "  227  91   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 241 242 193 232 234 222 211 222 217\n",
      "  229 100   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 213 243 197 224 221 221 213 225 222\n",
      "  230 115   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 224 241 210 221 220 220 216 230 224\n",
      "  232 112   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 243 252 215 238 235 229 228 237 229\n",
      "  244 129   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 204 181 199 186 185 208 206 197 209\n",
      "  214  86   0   0   0   0   0   0   0   0]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.imshow(train_images[50])\n",
    "print(train_images[50])\n",
    "print(train_labels[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data, between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(),\n",
    "                         keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "                         keras.layers.Dense(10,activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1874 - acc: 0.9286\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1830 - acc: 0.9303\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1777 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1739 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1698 - acc: 0.9362\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1647 - acc: 0.9375\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1629 - acc: 0.9380\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1571 - acc: 0.9404\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1540 - acc: 0.9427\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1507 - acc: 0.9432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0559751d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.3941 - acc: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3940699896275997, 0.8855]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6570616e-11 1.3370806e-14 4.4217035e-12 1.5085743e-17 1.2054378e-15\n",
      " 6.3406465e-06 1.9450086e-12 9.7718977e-05 3.1163335e-14 9.9989593e-01]\n"
     ]
    }
   ],
   "source": [
    "print(classify[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6570616e-11, 1.3370806e-14, 4.4217035e-12, 1.5085743e-17,\n",
       "       1.2054378e-15, 6.3406465e-06, 1.9450086e-12, 9.7718977e-05,\n",
       "       3.1163335e-14, 9.9989593e-01], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_im,training_lab),(test_im,test_lab) = df.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  48  88  54  25  19   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   1   1   1   0   0 206 204 106 163 178 157 163 171 119  39   0   0\n",
      "    2   1   1   1   1   1   1   1   0   0]\n",
      " [  0   0   0   0   0  84 204   0   0   0   1  57  91  77  99 138  94   7\n",
      "    0   0   0   0   0   0   0   0   1   3]\n",
      " [ 51  43  27  27  28 254  31   0   4   0   0   0  16 121  84  19  63 110\n",
      "   31   0   0   0   0   0   0   0   0   0]\n",
      " [137 202 133 108  97 146  71  78  82  86  85 105 118 139 143 126 162 176\n",
      "  135  69  76  71  91  99 103  94  99  54]\n",
      " [  0 110 186 205 203 193 191 178 204 172 175 175 177 183 189 190 197 196\n",
      "  192 182 186 185 184 182 178 168 159  77]\n",
      " [  0   0   0   4  51  69  92 108 112 115 112 111 112  90  77  62  44  36\n",
      "   32  35  27  25  19  14   5   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.imshow(training_im[30])\n",
    "print(training_im[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_im = training_im/255.0\n",
    "test_im = test_im/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.5239 - acc: 0.8178\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3739 - acc: 0.8648\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3335 - acc: 0.8789\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3091 - acc: 0.8868\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2909 - acc: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d056e61630>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_im,training_lab,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.3578 - acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.357829367184639, 0.87]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_im,test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(test_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4652878e-05, 4.9205287e-06, 9.9702358e-02, 1.6318142e-04,\n",
       "       8.6461437e-01, 7.1618792e-12, 3.5478830e-02, 2.4514993e-15,\n",
       "       2.1639529e-05, 1.7541383e-14], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(test_lab[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callbacks(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if(logs.get('loss')<0.3):\n",
    "            print('\\nThe loss has gotten low, so halting training')\n",
    "            self.model.stop_training =True\n",
    "callback_ = callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4697 - acc: 0.8320\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3547 - acc: 0.8702\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3200 - acc: 0.8814\n",
      "Epoch 4/30\n",
      "59488/60000 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.8902\n",
      "The loss has gotten low, so halting training\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2973 - acc: 0.8901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d005f10780>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion = keras.datasets.fashion_mnist\n",
    "(train_im,train_lab),(test_im,test_lab) = fashion.load_data()\n",
    "train_im = train_im/255.0\n",
    "test_im = test_im/255.0\n",
    "cmod = keras.models.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])\n",
    "cmod.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "cmod.fit(train_im,train_lab,epochs=30,callbacks=[callback_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/sample - loss: 0.3536 - acc: 0.8734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35356350271701814, 0.8734]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmod.evaluate(test_im,test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cmod.predict(test_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.9627191e-08, 8.2906270e-14, 6.7908603e-09, 7.7167205e-12,\n",
       "       2.5954511e-10, 2.8815637e-07, 2.8145561e-08, 8.1880962e-08,\n",
       "       9.9999952e-01, 4.8399372e-08], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lab[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.callbacks.Cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST handwriting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2\n",
    "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "\n",
    "It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
    "When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "I've started the code for you below -- how would you finish it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "handwrite = keras.datasets.mnist\n",
    "(train_im,train_labels),(test_im,test_labels) = handwrite.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38\n",
      "  190  25   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  13  25  10   0   0   0   0   0   0   0   0   0   0   0 112\n",
      "  252 125   4   0   0   0   0   0   0   0]\n",
      " [  0   0   0 132 252 113   0   0   0   0   0   0   0   0   0   0   0  61\n",
      "  252 252  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0 132 252 240  79   0   0   0   0   0   0   0   0   0   0  84\n",
      "  252 252  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0 132 252 252 238  52   0   0   0   0   0   0   0   0  12 198\n",
      "  252 252 122   0   0   0   0   0   0   0]\n",
      " [  0   0   0  99 252 252 252 181  17   0   0   0   0   0   0   0  49 252\n",
      "  252 252 122   0   0   0   0   0   0   0]\n",
      " [  0   0   0   3 125 252 252 252 100   0   0   0   0   0   0   0  26 218\n",
      "  252 252  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  15 216 252 252 207  19   0   0   0   0   0   0  49 252\n",
      "  252 252  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 157 252 252 252  48   0   0   0   6 109 109 194 252\n",
      "  252 252  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 100 252 252 252 105   0  58 116 128 252 252 252 252\n",
      "  252 212  19   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 164 253 253 253 253 253 253 255 253 253 253 253\n",
      "  253 253  99   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  49 252 252 252 252 252 252 253 252 252 252 252\n",
      "  252 252 155   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  49 252 252 252 252 252 252 217 216 141 126 252\n",
      "  252 252 155   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  49 252 252 252 234 204  89   0   0   0  49 252\n",
      "  252 252 155   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  14 158 192 151  45   0   0   0   0   0  49 252\n",
      "  252 252 225  17   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  49 252\n",
      "  252 252 252  23   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  33 228\n",
      "  252 252 252 157   4   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55\n",
      "  229 252 252 252  11   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   53 232 252 252  63   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  90 206 131  11   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]] \n",
      " 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.imshow(train_im[20])\n",
    "print(train_im[20],'\\n',train_labels[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data():\n",
    "    class mycallback(keras.callbacks.Callback):\n",
    "        def epoch_on_end(self,epoch,logs={}):\n",
    "            if(logs.get('loss')>0.02):\n",
    "                print('\\nThe accuracy got above 99% - Training Stopped')\n",
    "                self.model.stop_training = True\n",
    "    callback_ = mycallback()\n",
    "    (train_im,train_labels),(test_im,test_labels) = handwrite.load_data()\n",
    "    train_im,test_im=train_im/255.0,test_im/255.0\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_im,train_labels,epochs=15,callbacks=[callback_])\n",
    "    print()\n",
    "    model.evaluate(test_im,test_labels)\n",
    "    classifications = model.predict(test_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2577 - acc: 0.9262\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1127 - acc: 0.9662\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0781 - acc: 0.9762\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0573 - acc: 0.9822\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0449 - acc: 0.9860\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0358 - acc: 0.9887\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0288 - acc: 0.9910\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0235 - acc: 0.9927\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0195 - acc: 0.9938\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0134 - acc: 0.9958\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0075 - acc: 0.9977\n",
      "\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.1044 - acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot,graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN convulutional_Neural_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_im,train_lab),(test_im,test_lab) = fashion_mnist.load_data()\n",
    "train_im = train_im.reshape(60000,28,28,1,)\n",
    "test_im = test_im.reshape(10000,28,28,1)\n",
    "train_im,test_im = train_im/255.0,test_im/255.0\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 37s 614us/sample - loss: 0.3917 - acc: 0.8619\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 496us/sample - loss: 0.2691 - acc: 0.9026\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 0.2238 - acc: 0.9178\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 0.1905 - acc: 0.9299\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 25s 420us/sample - loss: 0.1615 - acc: 0.9410\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.2527 - acc: 0.9138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2527387261658907, 0.9138]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_im,train_lab,epochs=5)\n",
    "model.evaluate(test_im,test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
